{"cells":[{"cell_type":"code","source":["# Load a dataframe from a CSV file (with header line).  Change the filename to one that matches your S3 bucket.\neventDF = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferSchema='true').load('/mnt/S3/data/dataSetEvents.csv')\neventDF = eventDF.dropDuplicates()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Examine the data, and field/column names\ndisplay(eventDF)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Examine the schema (to see the inferred types)\neventDF.printSchema()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Show info for a single field/column\neventDF.describe('year').show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Count for each value in the make field/column\neventDF.groupBy('make').count().orderBy('make')"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["display(eventDF.groupBy('make').count().orderBy('make'))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Let's get the possible makes using distinct()\neventDF.select('make').distinct().orderBy('make')"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":[" display(eventDF.select('make').distinct().orderBy('make'))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# If we collect up all the values from the DataFrame, what do we get?\neventDF.select('make').distinct().orderBy('make').collect()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# How amny unique VINs are referenced in the data?\neventDF.select('vin').distinct().count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# We can select multiple fields, and group them, just like in SQL\nmakeModelDF = eventDF.select('make', 'model').groupBy('make', 'model').count().orderBy('model', 'make')"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["makeModelDF.printSchema()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["makeModelDF.take(5)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Grab all the VINs with non-zero price.\nvinPriceDF = eventDF.select('vin', 'price').filter(eventDF.price > 0)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["display(vinPriceDF)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# DataFrame API has crosstab()\ndisplay(eventDF.crosstab('make', 'model'))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# We can convert a DataFrame to an RDD\nmakeModelRDD = eventDF.rdd.map(lambda row: (row['make'], row['model']))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["makeModelRDD.take(5)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# We can convert a Row object to a dictionary\nmakeModelAsDictRDD = eventDF.rdd.map(lambda row: row.asDict())"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["makeModelAsDictRDD.take(5)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["eventDF.registerTempTable(\"table1\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#q1\neventDF1 = eventDF.select('vin', 'price', 'make', 'model').distinct()\neventDF1 = eventDF1.filter(eventDF1.price > 0)\neventDF1.registerTempTable(\"table1\")\n\npricequeryDF = sqlContext.sql(\"SELECT make, model, MIN(price) AS MinPrice, MAX(price) AS MaxPrice, AVG(price) AS AvgPrice FROM table1 GROUP BY make, model\")\ndisplay(pricequeryDF)\n\n#pricequeryDF.repartition(1).write.format('com.databricks.spark.csv').options(header='true').save('/mnt/S3/output/Spark3price')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#q2\neventDF2 = eventDF.select('vin', 'mileage', 'year').distinct()\neventDF2 = eventDF2.filter(eventDF2.mileage > 0)\neventDF2.registerTempTable(\"table2\")\n\nmilesqueryDF = sqlContext.sql(\"SELECT year, MIN(mileage) AS MinMiles, MAX(mileage) AS MaxMiles, AVG(mileage) AS AvgMiles FROM table2 GROUP BY year ORDER BY AvgMiles desc\")\ndisplay(milesqueryDF)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#q3\neventqueryDF = eventDF.crosstab('vin','event')\ndisplay(eventqueryDF)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["pricequeryDF.repartition(1).write.format('com.databricks.spark.csv').options(header='true').save('/mnt/S3/output/SparkHW3price')\nmilesqueryDF.repartition(1).write.format('com.databricks.spark.csv').options(header='true').save('/mnt/S3/output/SparkHW3miles')\neventqueryDF.repartition(1).write.format('com.databricks.spark.csv').options(header='true').save('/mnt/S3/output/SparkHW3event')\n"],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"Datasets (1)","notebookId":1870371745567075},"nbformat":4,"nbformat_minor":0}
